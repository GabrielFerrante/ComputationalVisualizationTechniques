{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1687c8f5",
   "metadata": {},
   "source": [
    "# DESCRIÇÃO DO TRABALHO\n",
    "\n",
    "Nestre trabalho, vou procurar apresentar de forma visualmente adequada a distribuição de porcentagens de confianças das predições das classes na detecção de objetos com YOLO. É de interesse do pesquisador de detecção de objetos, além de saber se o modelo usado acertou ou não na predição da classe do objeto, saber os indices de confianças para as demais classes, pois em alguns casos, apesar do modelo ter acertado a classe do objeto, ele pode ter quase errado ou confundido.\n",
    "\n",
    "\n",
    "Por motivos de limitações de recursos (Não possuir GPU para treinar um modelo) e tempo, usarei um modelo pré-treinado do Yolo feito com o Dataset COCO. Isso não afeta o trabalho, pois a visualização das predições não dependem de qual modelo está sendo utilizado. É utilizado 10 imagens das 10 classes de animais do COCO Dataset, que estão em diversos cenários. As classes são:\n",
    "\n",
    "'bird','cat','dog','horse','sheep','cow','elephant','bear','zebra','giraffe'\n",
    "\n",
    "\n",
    "Será disponibilizado no .zip da entrega:\n",
    "\n",
    "Um arquivo __.ipynb__ gerado pelo COLAB com a execução dos códigos deste relatório\n",
    "Uma pasta de anotações do COCO Dataset (mas pode ser baixada pelo arquivo do COLAB)\n",
    "Uma pasta de arquivos de configuração da rede Yolo (.cfg e .names)\n",
    "Arquivo __yolov4.weights__ que são os pesos da rede pré-treinada (mas pode ser baixada pelo arquivo do COLAB)\n",
    "Um CSV com os dados finais\n",
    "Este arquivo\n",
    "\n",
    "\n",
    "\n",
    "# Download das imagens de validação\n",
    "\n",
    "Para baixar as imagens, precisamos utilizar a pasta de anotações do COCO Dataset (Disponível na entrega) ou baixar e extrair pelo Colab com o comando:\n",
    "\n",
    "``!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip``\n",
    "\n",
    "``!unzip annotations_trainval2017.zip``\n",
    "\n",
    "\n",
    "Agora você precisa instalar o pacote da api do COCO para realizar o download das imagens no Colab:\n",
    "\n",
    "`` !pip install pycocotools  ``\n",
    "\n",
    "\n",
    "Fazer os imports das dependências\n",
    "\n",
    "``\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab.patches import cv2_imshow\n",
    "import zipfile\n",
    "from os.path import isfile, join\n",
    "import csv \n",
    "from pycocotools.coco import COCO\n",
    "import requests\n",
    "``\n",
    "\n",
    "e por fim, com as anotações e o pacote da api instalado, executar o código abaixo.\n",
    "\n",
    "```\n",
    "def createDirectory(name, animal):\n",
    "    import os\n",
    "\n",
    " \n",
    "    path = name\n",
    "    access_rights = 0o755\n",
    "    try:\n",
    "        os.mkdir(path, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path)\n",
    "        \n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "\n",
    "    os.chdir(name)\n",
    "\n",
    "\n",
    "    path = animal\n",
    "    access_rights = 0o755\n",
    "    try:\n",
    "        os.mkdir(path, access_rights)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path)\n",
    "        \n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "\n",
    "    os.chdir(\"..\")\n",
    "```\n",
    "\n",
    "```\n",
    "def downloadValid(animal, coco, index):\n",
    "    createDirectory('valid/', animal)\n",
    "    cats = coco.loadCats(coco.getCatIds())\n",
    "    nms=[cat['name'] for cat in cats]\n",
    "\n",
    "    catIds = coco.getCatIds(catNms=[animal])\n",
    "\n",
    "    imgIds = coco.getImgIds(catIds=catIds )\n",
    "    images = coco.loadImgs(imgIds)\n",
    "\n",
    "    i = 1\n",
    "    for im in images:\n",
    "        if i <= 4:\n",
    "            img_data = requests.get(im['coco_url']).content\n",
    "            \n",
    "            with open('valid/'+ animal + '/'+ animal+'_'+im['file_name'], 'wb') as handler:\n",
    "                handler.write(img_data)\n",
    "            \n",
    "            time.sleep(3)    \n",
    "            i = i + 1\n",
    "        else:\n",
    "            break\n",
    "```\n",
    "\n",
    "``\n",
    "coco = COCO('annotations/instances_val2017.json')\n",
    "animals = [ 'bird',\n",
    "            'cat',\n",
    "            'dog',\n",
    "            'horse',\n",
    "            'sheep',\n",
    "            'cow',\n",
    "            'elephant',\n",
    "            'bear',\n",
    "            'zebra',\n",
    "            'giraffe']\n",
    "for item in animals:\n",
    "  downloadValid(item, coco, animals.index(item))\n",
    "``\n",
    "\n",
    "\n",
    "Irá ser criado no diretório raiz, uma pasta chamada __valid__ com 10 sub-pastas, referenciando cada classe e suas imagens.\n",
    "\n",
    "\n",
    "# Passos para extrair as confianças das predições do modelo Yolo com OpenCV\n",
    "\n",
    "Para a execução, utilizar o Google Colab sem GPU pois o modelo já está treinado. Lembrando que estou interessando em apresentar as confianças de cada predição feita, portanto, será mostrado o processo de predição mas não códigos de como apresentar as caixas delimitadoras (bounding-boxes). \n",
    "\n",
    "No ambiente, é necessário instalar o Open CV na versão 4.4, que suporta o Yolo.\n",
    "\n",
    "__!pip install opencv-python==4.4.0.40__\n",
    "\n",
    "\n",
    "Verificando a versão do open cv\n",
    "\n",
    "``print(cv2.__version__)``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dcfe14",
   "metadata": {},
   "source": [
    "Baixe os pesos do modelo pré-treinado.\n",
    "\n",
    "``!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights``\n",
    "\n",
    "__yolov4.weights__ (São os pesos da rede neural convolucional)\n",
    "\n",
    "Fazer o upload dos arquivos da pasta cfg (na entrega), contendo os arquivos (O Colab não irá deixar fazer o upload da pasta, portanto, cria uma pasta 'cfg' e dentro dela faça o upload dos dois arquivos dentro dela)\n",
    "\n",
    "__yolov4.cfg__ (Arquivo de configuração da rede)\n",
    "__coco.names__ (Contém os nomes de todas as classes treinadas, inclusive as classes que pretendo testar)\n",
    "\n",
    "Guardando em uma lista, as classes contidas no arquivo __coco.names__ (lembrando que no google Colab, o diretório raiz de manipulação é __/content/__) \n",
    "\n",
    "Obs: existem 80 classes neste modelo pré-treinado, então haverá várias classes onde as futuras confianças assumirão valor 0%, pois irei somente utilizar as imagens de animais.\n",
    "\n",
    "``\n",
    "labelsPath = os.path.sep.join(['/content/cfg', 'coco.names'])\n",
    "LABELS = open(labelsPath).read().strip().split('\\n')\n",
    "``\n",
    "\n",
    "Guardando os pesos e as configurações da cnn em duas varias respectivamente\n",
    "\n",
    "``\n",
    "weightsPath = os.path.sep.join(['/content', 'yolov4.weights'])\n",
    "configPath = os.path.sep.join(['/content/cfg', 'yolov4.cfg'])\n",
    "``\n",
    "\n",
    "Agora iremos criar a rede com o OpenCV e pegar somente as 3 camadas de saída\n",
    "\n",
    "``\n",
    "net = cv2.dnn.readNet(configPath, weightsPath)\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "``\n",
    "\n",
    "\n",
    "Agora iremos criar duas funções, uma para criar um CSV final, com as predições e outra função para gerar as predições.\n",
    "\n",
    "Para o trabalho, estes dados serão exportados para um __CSV__, que facilitará as próximas etapas do projeto da disciplina. Pois não dependerá de executar mais de uma vez códigos de download de imagens e a execução destes passos e sim, só se preocupar com os dados finais. Além disso, facilitará a exportação para usar no Jupyter.\n",
    "\n",
    "Será armazenado em um __CSV__ os seguintes dados: Nome da imagem processada, a  camada de saída da rede neural e 80 colunas, que correspondem cada classe do modelo pré-treinado usado. Totalizando 82 COLUNAS. \n",
    "\n",
    "O parâmetro Threshold, define uma porcentagem mínima de confiança para filtrar as confianças baixas. No caso iremos definir como 0.4 (tudo acima de 40% de confiança será retornado). Este valor pode ser alterado para ver o quão o modelo consegue de precisão máxima sem perder todas as predições e depende do problema em questão.\n",
    "\n",
    "O YoloV4 possui 3 camadas de saída, e elas retornam várias predições. Estas predições são formadas por arrays que possuem a confiança para cada classe detectada. Cada array possui várias posições, as 4 primeiras posições do array identificam as coordenadas na imagem para a formação da caixa delimitadora, a partir do indice 5, ficam as confianças para cada classe do modelo para aquela predição executada.\n",
    "\n",
    "\n",
    "PRÉ-PROCESSAMENTO\n",
    "\n",
    "É aplicado a função do OpenCV denominada __cv2.dnn.blobFromImage__. Esta função aplica dois pré-processamentos, o Mean subtraction e o Scaling.\n",
    "\n",
    "A Mean subtraction é usada para ajudar a reduzir o impacto das mudanças de iluminação nas imagens de entrada. \n",
    "Primeiro calculamos a intensidade de iluminação média dos pixels em todas as imagens para cada um dos três canais (RGB).\n",
    "\n",
    "Nesta etapa, logo após, aplicaremos o Scaling. Ele procura realizar uma normalização dos resutlados do Mean Subtraction de acordo com um fator de escala.  Este valor padrão é 1.0 (ou seja, sem mudança na escala), mas podemos fornecer outro valor também. Ele pode ser divisível pelo desvio padrão das dimensões das imagens do conjunto.\n",
    "\n",
    "A função recebe como parâmetros:\n",
    "a imagem, \n",
    "o fator de escala (1 / 255.0), \n",
    "uma tupla com as dimensões desejadas (Para o YoloV4 é interessante utilizar 416x416), \n",
    "se irá ser utilizado o Mean Subtraction (definindo swapRB como True),\n",
    "se a imagem vai ser recortada ou não\n",
    "\n",
    "\n",
    "\n",
    "(Fonte: https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/ e https://docs.opencv.org/3.4.15/d6/d0f/group__dnn.html)\n",
    "\n",
    "\n",
    "```\n",
    "rows = [] \n",
    "def createCSV(rows):\n",
    "  \n",
    "  Details = ['ImageName', 'LayerOutput']\n",
    "  for item in LABELS:\n",
    "    Details.append(item)\n",
    "  \n",
    "  with open('confiancasDasDeteccoes.csv', 'w') as f: \n",
    "    write = csv.writer(f) \n",
    "    write.writerow(Details) \n",
    "    write.writerows(rows)\n",
    "\n",
    "def gerandoConfiancas(imagem, imgName ):\n",
    "\n",
    "  threshold = 0.2\n",
    "  confiances = []\n",
    "  idClasses = []\n",
    "  dados = []\n",
    "  currentLayer = 0\n",
    "\n",
    "  blob = cv2.dnn.blobFromImage(imagem, 1 / 255.0, (416,416), swapRB=True, crop=False)\n",
    "  net.setInput(blob)\n",
    "  layer_outputs = net.forward(ln)\n",
    "\n",
    "  for output in layer_outputs:\n",
    "    for detection in output:\n",
    "      scores = detection[5:] #Filtrando somente as confianças\n",
    "      classeID = np.argmax(scores)\n",
    "      confiance = scores[classeID]\n",
    "      dados = []\n",
    "      if confiance > threshold: #aplicando a filtragem do Threshold\n",
    "          dados = [imgName, currentLayer]\n",
    "          for item in scores:\n",
    "            dados.append(item)\n",
    "          print('scores: '+ str(scores)) #Apresenta todas as confianças\n",
    "          print('classe mais provável: '+ str(classeID)) #Apresenta o index da classe.\n",
    "          print('confiança: '+ str(confiance))#Apresenta a confiança daquela classe que foi apontada como a mais confiante\n",
    "\n",
    "          confiances.append(float(confiance))\n",
    "          idClasses.append(classeID)\n",
    "        \n",
    "          rows.append(dados)\n",
    "    \n",
    "    currentLayer = currentLayer + 1\n",
    "    \n",
    "    \n",
    "```\n",
    "\n",
    "Executando as funções. Ao final, será gerado um CSV e poderá ser baixado, clicando nas opções do arquivo. \n",
    "\n",
    "```\n",
    "animals = [ 'bird',\n",
    "            'cat',\n",
    "            'dog',\n",
    "            'horse',\n",
    "            'sheep',\n",
    "            'cow',\n",
    "            'elephant',\n",
    "            'bear',\n",
    "            'zebra',\n",
    "            'giraffe']\n",
    "\n",
    "for item in animals:\n",
    "\n",
    "  mypath = f\"/content/valid/{item}\"\n",
    "  onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "  for img in onlyfiles:\n",
    "    imagem = cv2.imread(f'/content/valid/{item}/{img}')\n",
    "    gerandoConfiancas(imagem, img)\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b242dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
