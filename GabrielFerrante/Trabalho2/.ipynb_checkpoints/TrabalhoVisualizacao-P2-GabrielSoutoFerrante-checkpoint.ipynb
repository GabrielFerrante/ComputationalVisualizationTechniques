{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cff9cc9f",
   "metadata": {},
   "source": [
    "# Descrição do Trabalho - Parte 2\n",
    "\n",
    "Aluno: Gabriel Souto Ferrante - 12620303\n",
    "\n",
    "Arquivos do .ZIP da entrega:\n",
    "<ul>\n",
    "    <li> Este Notebook com as informações do relatório. </li>\n",
    "    <li> Um Notebook do COLAB com a execução prática. </li>\n",
    "</ul> \n",
    "\n",
    "As etapas desta entrega são:\n",
    "\n",
    "1 - Com seus dados pré-processados, identifique em qual grupo taxonômico seu conjunto de dados se encaixa (p.e. categórico, numérico, híbrido, etc...). Justifique com uma explicação dos seus dados. Vide o catálogo From Data to Viz\n",
    "\n",
    "2 - Identifique qual mapeamento visual é o mais indicado para os seus dados e, se você julgar que aquele paradigma visual realmente é a melhor escolha, apresente seus dados com a visualização\n",
    "\n",
    "obs: Caso decida utilizar outra visualização, justifique a escolha\n",
    "\n",
    "3 - Descreva os insights que a visualização proporcionou para os seus dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817a60a",
   "metadata": {},
   "source": [
    "# Sobre os dados e observações\n",
    "\n",
    "O conjunto de dados utilizado para aplicar os processos de visualização é composto por 50 imagens de cada uma das 10 classes referentes à animais do COCO Dataset, totalizando 500 imagens. Houve alguns insights e modificações na proposta, e por fim, escolhi utilizar a distâncias de cada imagem fazendo o uso de embeddings (vetores de características). Estas embeddings são calculadas utilizando uma rede neural convolucional EfficientNet-B0 pré-treinada com o conjunto ImageNet, implementada na biblioteca <strong>image_embeddings</strong> (https://github.com/rom1504/image_embeddings/tree/e6233e78b857285c32755587f585fa251cabae17). \n",
    "\n",
    "Logo após a criação das embeddings, é analisado a dimensionalidade, sendo 499 linhas por 1280 colunas. Para tratar dessa alta dimensionalidade, é utilizado o método de redução de dimensionalidade T-SNE para facilitar a implementação de visualização, gerando no final um conjunto com 499 linhas e 2 colunas. Após a redução, é acrescentado mais duas colunas, uma para identificação de qual imagem aquela embedding pertence e outra coluna para a classe original da imagem. Para informações detalhadas de implementação, consultar o Notebook do COLAB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0906373",
   "metadata": {},
   "source": [
    "# Etapa 1\n",
    "\n",
    "\n",
    "Seguindo os grupos taxonômicos do site From Data to Viz, o conjunto utilizado já redimensionado integra no grupo dos híbridos (númericos e categóricos). No conjunto possui 4 colunas, sendo duas númericas, uma identificadora e uma categórica:\n",
    "\n",
    "<ul>\n",
    "    <li>x (númerico)</li>\n",
    "    <li>y (númerico)</li>\n",
    "    <li>ImageName (Identificador)</li>\n",
    "    <li>ClasseOriginal (Categórico)</li>\n",
    "</ul>\n",
    "\n",
    "![alt text](GrupoTax.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e6f457",
   "metadata": {},
   "source": [
    "# Etapa 2\n",
    "\n",
    "A forma escolhida para apresentar os dados, é o Scatter Plot. Por ser uma ótima opção em apresentar conjuntos onde duas variáveis numéricas estão correlacionadas.\n",
    "\n",
    "![alt text](Scatter.png \"Title\")\n",
    "\n",
    "Além dessa visualização, é também de interesse utilizar um mecânismo de XAI (<i>eXplained Arctificial Inteligence</i>) para explicar como que o modelo classificou certa imagem para determinada classe e criou suas embeddings. Para isso, é utilizado a biblioteca <strong>SHAP</strong> (https://github.com/slundberg/shap). \n",
    "\n",
    "Abaixo é feito a explicação de classificação para duas imagens (bird_000000300155.jpg e bird_000000222235.jpg), uma que possui somente um pássaro e outra que possui um gato e um pássaro. A segunda possuindo mais interferências de oclusão (da vegetação), tornando o pássaro menos evidente.\n",
    "\n",
    "![alt text](Shap.png \"Title\")\n",
    "\n",
    "Os quadrantes em cores próximas ao vermelho identificam as características que tiveram mais impactos na classficação, o inverso dos quadrantes com cores próximas ao azul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c7f01c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
